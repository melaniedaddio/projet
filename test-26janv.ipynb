{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10581129,"sourceType":"datasetVersion","datasetId":6548345}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd  \nimport numpy as np  \nimport statsmodels.api as sm\nfrom numpy import median\nfrom numpy import mean\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/kaggle-cirrhosis'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression \nfrom xgboost import XGBClassifier\nimport xgboost as xgb\nfrom sklearn.metrics import log_loss, classification_report \nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# https://www.kaggle.com/code/abhirupghosh184098/cirrhosis-predictor-eda-ensemble-nn\n# https://www.kaggle.com/code/ashishkumarak/ps3e26-liver-cirrhosis-eda-model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/kaggle-cirrhosis/train_df_clean.csv\", \n                      delimiter = \",\",\n                      header = 0)\n\ntest = pd.read_csv(\"/kaggle/input/kaggle-cirrhosis/test.csv\", \n                      delimiter = \",\",\n                      header = 0)\n\ntrain.shape, test.shape # manque la colonne Status","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Partie Train","metadata":{}},{"cell_type":"code","source":"train1 = train.copy()\ntrain1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train1.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in train1.select_dtypes(include=['object']).columns:\n    unique_values = ', '.join(map(str, train1[col].unique()))\n    print(f\"Colonne '{col}': {unique_values}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"(train1.isnull().sum() / len(train1) * 100).round(2)\n#(train.isna().sum() / len(train) * 100).round(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Colonnes Object (Mode)","metadata":{}},{"cell_type":"code","source":"# mode pour les Hommes et Femmes selon la cible Status pour différentes colonnes (ancienne méthode)\n# par la suite, Status remplacé par Stage\n\n# DRUG:\n# mode pour les Hommes selon la cible Status:\n#train[train['Sex'] == 'M'].groupby('Status')['Drug'].agg(lambda x: x.mode().iloc[0])\n# mode pour les Femmees selon la cible Status:\n#train[train['Sex'] == 'F'].groupby('Status')['Drug'].agg(lambda x: x.mode().iloc[0])\n\n# ASCITES:\n# mode pour les Hommes selon la cible Status:\n#train[train['Sex'] == 'M'].groupby('Status')['Ascites'].agg(lambda x: x.mode().iloc[0])\n# mode pour les Femmes selon la cible Status:\n#train[train['Sex'] == 'F'].groupby('Status')['Ascites'].agg(lambda x: x.mode().iloc[0])\n\n# HEPATOMEGALY:\n# mode pour les Hommes selon la cible Status:\n#train[train['Sex'] == 'M'].groupby('Status')['Hepatomegaly'].agg(lambda x: x.mode().iloc[0])\n# mode pour les Femmes selon la cible Status:\n#train[train['Sex'] == 'F'].groupby('Status')['Hepatomegaly'].agg(lambda x: x.mode().iloc[0])\n\n# SPIDERS:\n# mode pour les Hommes selon la cible Status:\n#train[train['Sex'] == 'M'].groupby('Status')['Spiders'].agg(lambda x: x.mode().iloc[0])\n# mode pour les Femmes selon la cible Status:\n#train[train['Sex'] == 'F'].groupby('Status')['Spiders'].agg(lambda x: x.mode().iloc[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Drug","metadata":{}},{"cell_type":"code","source":"# mode pour les Hommes selon la cible Stage:\ntrain1[train1['Sex'] == 'M'].groupby('Stage')['Drug'].agg(lambda x: x.mode().iloc[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# mode pour les Femmees selon la cible Stage:\ntrain1[train1['Sex'] == 'F'].groupby('Stage')['Drug'].agg(lambda x: x.mode().iloc[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Ascites","metadata":{}},{"cell_type":"code","source":"# mode pour les Hommes selon la cible Stage:\ntrain1[train1['Sex'] == 'M'].groupby('Stage')['Ascites'].agg(lambda x: x.mode().iloc[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# mode pour les Femmes selon la cible Stage:\ntrain1[train1['Sex'] == 'F'].groupby('Stage')['Ascites'].agg(lambda x: x.mode().iloc[0])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Hepatomegaly","metadata":{}},{"cell_type":"code","source":"# mode pour les Hommes selon la cible Stage:\ntrain1[train1['Sex'] == 'M'].groupby('Stage')['Hepatomegaly'].agg(lambda x: x.mode().iloc[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# mode pour les Femmes selon la cible Stage:\ntrain1[train1['Sex'] == 'F'].groupby('Stage')['Hepatomegaly'].agg(lambda x: x.mode().iloc[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Spiders","metadata":{}},{"cell_type":"code","source":"# mode pour les Hommes selon la cible Stage:\ntrain1[train1['Sex'] == 'M'].groupby('Stage')['Spiders'].agg(lambda x: x.mode().iloc[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# mode pour les Femmes selon la cible Stage:\ntrain1[train1['Sex'] == 'F'].groupby('Stage')['Spiders'].agg(lambda x: x.mode().iloc[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# modes_drug = {\n#     ('M', 'C'): 'Placebo',\n#     ('M', 'CL'): 'D-penicillamine',\n#     ('M', 'D'): 'D-penicillamine',\n#     ('F', 'C'): 'D-penicillamine',\n#     ('F', 'CL'): 'D-penicillamine',\n#     ('F', 'D'): 'D-penicillamine'\n# }\n\n# modes_ascites = {\n#     ('M', 'C'): 'N',\n#     ('M', 'CL'): 'N',\n#     ('M', 'D'): 'N',\n#     ('F', 'C'): 'N',\n#     ('F', 'CL'): 'N',\n#     ('F', 'D'): 'N'\n# }\n\n# modes_hepatomegaly = {\n#     ('M', 'C'): 'N',\n#     ('M', 'CL'): 'Y',\n#     ('M', 'D'): 'Y',\n#     ('F', 'C'): 'N',\n#     ('F', 'CL'): 'Y',\n#     ('F', 'D'): 'Y'\n# }\n\n# modes_spiders = {\n#     ('M', 'C'): 'N',\n#     ('M', 'CL'): 'N',\n#     ('M', 'D'): 'N',\n#     ('F', 'C'): 'N',\n#     ('F', 'CL'): 'N',\n#     ('F', 'D'): 'N'\n# }\n\n# def na_par_mode(row):\n#     key = (row['Sex'], row['Status'])\n#     if pd.isna(row['Drug']):\n#         row['Drug'] = modes_drug[key]\n#     if pd.isna(row['Ascites']):\n#         row['Ascites'] = modes_ascites[key]\n#     if pd.isna(row['Hepatomegaly']):   ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# modes pour chaque colonne selon la modalité 'Stage'\nmodes_drug = {\n    ('M', 1.0): 'Placebo',\n    ('M', 2.0): 'D-penicillamine',\n    ('M', 3.0): 'D-penicillamine',\n    ('M', 4.0): 'D-penicillamine',\n    ('F', 1.0): 'D-penicillamine',\n    ('F', 2.0): 'D-penicillamine',\n    ('F', 3.0): 'D-penicillamine',\n    ('F', 4.0): 'Placebo'\n}\n\nmodes_ascites = {\n    ('M', 1.0): 'N',\n    ('M', 2.0): 'N',\n    ('M', 3.0): 'N',\n    ('M', 4.0): 'N',\n    ('F', 1.0): 'N',\n    ('F', 2.0): 'N',\n    ('F', 3.0): 'N',\n    ('F', 4.0): 'N'\n}\n\nmodes_hepatomegaly = {\n    ('M', 1.0): 'N',\n    ('M', 2.0): 'N',\n    ('M', 3.0): 'N',\n    ('M', 4.0): 'Y',\n    ('F', 1.0): 'N',\n    ('F', 2.0): 'N',\n    ('F', 3.0): 'N',\n    ('F', 4.0): 'Y'\n}\n\nmodes_spiders = {\n    ('M', 1.0): 'N',\n    ('M', 2.0): 'N',\n    ('M', 3.0): 'N',\n    ('M', 4.0): 'N',\n    ('F', 1.0): 'N',\n    ('F', 2.0): 'N',\n    ('F', 3.0): 'N',\n    ('F', 4.0): 'N'\n}\n\ndef na_par_mode(row):\n    key = (row['Sex'], row['Stage'])\n    if pd.isna(row['Drug']):\n        row['Drug'] = modes_drug[key]\n    if pd.isna(row['Ascites']):\n        row['Ascites'] = modes_ascites[key]\n    if pd.isna(row['Hepatomegaly']):\n        row['Hepatomegaly'] = modes_hepatomegaly[key]\n    if pd.isna(row['Spiders']):\n        row['Spiders'] = modes_spiders[key]\n    return row\n\ntrain1 = train1.apply(na_par_mode, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Colonnes Numériques (Médiane)","metadata":{}},{"cell_type":"code","source":"# la médiane pour chaque colonne numérique, par sexe et par modalité de Stage\nmedianes = train1.groupby(['Sex', 'Stage'])[['Cholesterol', 'Copper', 'Alk_Phos', \n                                             'SGOT', 'Tryglicerides', 'Platelets', \n                                             'Prothrombin']].median()\n\nmedianes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"moyennes = train1.groupby(['Sex', 'Stage'])[['Cholesterol', 'Copper', 'Alk_Phos', \n                                             'SGOT', 'Tryglicerides', 'Platelets', \n                                             'Prothrombin']].mean().round(2)\nmoyennes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"colonnes_a_traiter = ['Cholesterol', 'Copper', 'Alk_Phos', \n                       'SGOT', 'Tryglicerides', 'Platelets', \n                       'Prothrombin']\n\ndef na_par_mediane(row):\n    for col in colonnes_a_traiter:\n        if pd.isna(row[col]):\n            row[col] = medianes.loc[(row['Sex'], row['Stage']), col]\n    return row\n\ntrain1 = train1.apply(na_par_mediane, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train1.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Normalisation avec PowerTransformer: pour rendre les données plus gaussiennes","metadata":{}},{"cell_type":"code","source":"train2 = train1.copy()\n# Normalisation avec PowerTransformer: pour rendre les données plus gaussienne\ncolonnes_to_normalize = ['Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos', \n                        'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']\n\ntransformer = PowerTransformer(method = 'yeo-johnson')\ntrain2[colonnes_to_normalize] = transformer.fit_transform(train2[colonnes_to_normalize])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Encoding","metadata":{}},{"cell_type":"code","source":"for col in train2.select_dtypes(include=['object']).columns:\n    unique_values = ', '.join(map(str, train2[col].unique()))\n    print(f\"Colonne '{col}': {unique_values}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train2['Stage'][:3]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Custom Mapping pour Stage car l'ordre a l'air d'avoir son importance \n# This encoding is particularly useful for ordinal variable where the order of categories is important\n# To make sure that the learning algorithm interprets the ordinal variables correctly, \n# we can map the categorical values to integer values manually. \nprint(train2['Stage'].unique())  \ntrain2['Stage'] = train2['Stage'].map({1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3})\nprint(train2['Stage'].unique())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# OneHot encoding pour les autres\n# Liste des colonnes catégoriques\ncolonnes_cat = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n\ntrain_encoded = pd.get_dummies(train2, columns=colonnes_cat, drop_first=False)\ntrain_encoded.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_encoded.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# la colonne cible avec Label Encoding\nlabel_encoder = LabelEncoder()\ntrain_encoded['Status_encoded'] = label_encoder.fit_transform(train_encoded['Status']) \ntrain_encoded.drop('Status', axis=1, inplace=True)\ntrain_encoded['Status_encoded'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# le modèle \nX = train_encoded.drop(['id', 'Status_encoded'], axis=1) \ny = train_encoded['Status_encoded']  \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=10000)\n# solver='lbfgs' par défaut\n\nmodel.fit(X_train, y_train)\n\ny_pred_proba = model.predict_proba(X_test)\n\nlogloss = log_loss(y_test, y_pred_proba)\nprint(f\"Log Loss: {logloss}\")\n\ny_pred = model.predict(X_test)\nprint(classification_report(y_test, y_pred, target_names=['C', 'CL', 'D']))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Autre méthode","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test['Drug'].replace('Drug', np.nan, inplace=True)\ntest['Spiders'].replace('C', np.nan, inplace=True)\nfor col in test.select_dtypes(include=['object']).columns:\n    unique_values = ', '.join(map(str, test[col].unique()))\n    print(f\"Colonne '{col}': {unique_values}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_drug = train.copy()\ntest_drug = test.copy()\n\n# KNNImputer pour les colonnes numériques pour l'imputation\nnum_cols = ['Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']\nimputer = KNNImputer(n_neighbors=122)\nimputer_test = KNNImputer(n_neighbors=100)\n\ntrain_drug[num_cols] = imputer.fit_transform(train_drug[num_cols])\ntest_drug[num_cols] = imputer_test.fit_transform(test_drug[num_cols])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_drug['Drug_missing'] = train_drug['Drug'].isna().astype(int)\n\nlabel_encoders = {}\ncategorical_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    train_drug[col] = train_drug[col].astype(str)  \n    train_drug[col] = le.fit_transform(train_drug[col])\n    label_encoders[col] = le\n\nnot_null_data = train_drug[train_drug['Drug_missing'] == 0]\nnull_data = train_drug[train_drug['Drug_missing'] == 1]\n\nif null_data.empty:\n    print(\"Aucune valeur manquante pour 'Drug'.\")\nelse:\n    features = [col for col in train_drug.columns if col not in ['Drug', 'Drug_missing', 'Status'] and train_drug[col].isna().sum() == 0]\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        not_null_data[features], not_null_data['Drug'], test_size=0.2, random_state=42\n    )\n    \n    randfor = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1)\n    param_grid = {\n        'criterion': ['gini', 'entropy'],\n        'max_depth': np.arange(1, 10)\n    }\n    gridmodel = GridSearchCV(randfor, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    gridmodel.fit(X_train, y_train)\n    \n    print(\"Meilleurs paramètres :\", gridmodel.best_params_)\n    best_model = gridmodel.best_estimator_\n    \n    test_predictions = best_model.predict(X_test)\n    accuracy = round((test_predictions == y_test).sum() / len(test_predictions), 3)\n    print(f\"Précision sur l'ensemble de test : {accuracy}\")\n\n    predicted_values = best_model.predict(null_data[features])\n    train_drug.loc[train_drug['Drug_missing'] == 1, 'Drug'] = predicted_values\n\ntrain_drug['Drug'] = label_encoders['Drug'].inverse_transform(train_drug['Drug'].astype(int))\n\ntrain_drug.drop('Drug_missing', axis=1, inplace=True)\ntrain_drug[['Drug']].head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_drug['Drug_missing'] = test_drug['Drug'].isna().astype(int)\n\nlabel_encoders = {}\ncategorical_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    test_drug[col] = test_drug[col].astype(str)  \n    test_drug[col] = le.fit_transform(test_drug[col])\n    label_encoders[col] = le\n\nnot_null_data = test_drug[test_drug['Drug_missing'] == 0]\nnull_data = test_drug[test_drug['Drug_missing'] == 1]\n\nif null_data.empty:\n    print(\"Aucune valeur manquante pour 'Drug'.\")\nelse:\n    features = [col for col in test_drug.columns if col not in ['Drug', 'Drug_missing', 'Status'] and test_drug[col].isna().sum() == 0]\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        not_null_data[features], not_null_data['Drug'], test_size=0.2, random_state=42\n    )\n    \n    randfor = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1)\n    param_grid = {\n        'criterion': ['gini', 'entropy'],\n        'max_depth': np.arange(1, 10)\n    }\n    gridmodel = GridSearchCV(randfor, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    gridmodel.fit(X_train, y_train)\n    \n    print(\"Meilleurs paramètres :\", gridmodel.best_params_)\n    best_model = gridmodel.best_estimator_\n    \n    test_predictions = best_model.predict(X_test)\n    accuracy = round((test_predictions == y_test).sum() / len(test_predictions), 3)\n    print(f\"Précision sur l'ensemble de test : {accuracy}\")\n\n    predicted_values = best_model.predict(null_data[features])\n    test_drug.loc[test_drug['Drug_missing'] == 1, 'Drug'] = predicted_values\n\ntest_drug['Drug'] = label_encoders['Drug'].inverse_transform(test_drug['Drug'].astype(int))\n\ntest_drug.drop('Drug_missing', axis=1, inplace=True)\ntest_drug[['Drug']].head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ascites = train.copy()\ntest_ascites = test.copy()\n\n# KNNImputer pour les colonnes numériques pour l'imputation\nnum_cols = ['Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']\nimputer = KNNImputer(n_neighbors=122)\n\ntrain_ascites[num_cols] = imputer.fit_transform(train_ascites[num_cols])\ntest_ascites[num_cols] = imputer_test.fit_transform(test_ascites[num_cols])\ntrain_ascites.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ascites['Ascites_missing'] = train_ascites['Ascites'].isna().astype(int)\n\nlabel_encoders = {}\ncategorical_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    train_ascites[col] = train_ascites[col].astype(str)  \n    train_ascites[col] = le.fit_transform(train_ascites[col])\n    label_encoders[col] = le\n\nnot_null_data = train_ascites[train_ascites['Ascites_missing'] == 0]\nnull_data = train_ascites[train_ascites['Ascites_missing'] == 1]\n\nif null_data.empty:\n    print(\"Aucune valeur manquante pour 'Ascites'.\")\nelse:\n    features = [\n        col for col in train_ascites.columns \n        if col not in ['Ascites', 'Ascites_missing', 'Status'] \n           and train_ascites[col].isna().sum() == 0\n    ]\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        not_null_data[features], \n        not_null_data['Ascites'], \n        test_size=0.2, \n        random_state=42\n    )\n    \n    randfor = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1)\n    param_grid = {\n        'criterion': ['gini', 'entropy'],\n        'max_depth': np.arange(1, 10)\n    }\n    gridmodel = GridSearchCV(randfor, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    gridmodel.fit(X_train, y_train)\n    \n    print(\"Meilleurs paramètres :\", gridmodel.best_params_)\n    best_model = gridmodel.best_estimator_\n    \n    test_predictions = best_model.predict(X_test)\n    accuracy = round((test_predictions == y_test).sum() / len(test_predictions), 3)\n    print(f\"Précision sur l'ensemble de test : {accuracy}\")\n\n    predicted_values = best_model.predict(null_data[features])\n    train_ascites.loc[train_ascites['Ascites_missing'] == 1, 'Ascites'] = predicted_values\n\ntrain_ascites['Ascites'] = label_encoders['Ascites'].inverse_transform(\n    train_ascites['Ascites'].astype(int)\n)\n\ntrain_ascites.drop('Ascites_missing', axis=1, inplace=True)\ntrain_ascites[['Ascites']].head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_ascites['Ascites_missing'] = test_ascites['Ascites'].isna().astype(int)\n\nlabel_encoders = {}\ncategorical_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    test_ascites[col] = test_ascites[col].astype(str)  \n    test_ascites[col] = le.fit_transform(test_ascites[col])\n    label_encoders[col] = le\n\nnot_null_data = test_ascites[test_ascites['Ascites_missing'] == 0]\nnull_data = test_ascites[test_ascites['Ascites_missing'] == 1]\n\nif null_data.empty:\n    print(\"Aucune valeur manquante pour 'Ascites'.\")\nelse:\n    features = [\n        col for col in test_ascites.columns \n        if col not in ['Ascites', 'Ascites_missing', 'Status'] \n           and test_ascites[col].isna().sum() == 0\n    ]\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        not_null_data[features], \n        not_null_data['Ascites'], \n        test_size=0.2, \n        random_state=42\n    )\n    \n    randfor = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1)\n    param_grid = {\n        'criterion': ['gini', 'entropy'],\n        'max_depth': np.arange(1, 10)\n    }\n    gridmodel = GridSearchCV(randfor, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    gridmodel.fit(X_train, y_train)\n    \n    print(\"Meilleurs paramètres :\", gridmodel.best_params_)\n    best_model = gridmodel.best_estimator_\n    \n    test_predictions = best_model.predict(X_test)\n    accuracy = round((test_predictions == y_test).sum() / len(test_predictions), 3)\n    print(f\"Précision sur l'ensemble de test : {accuracy}\")\n\n    predicted_values = best_model.predict(null_data[features])\n    test_ascites.loc[test_ascites['Ascites_missing'] == 1, 'Ascites'] = predicted_values\n\ntest_ascites['Ascites'] = label_encoders['Ascites'].inverse_transform(\n    test_ascites['Ascites'].astype(int)\n)\n\ntest_ascites.drop('Ascites_missing', axis=1, inplace=True)\n\ntest_ascites[['Ascites']].head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_hepatomegaly = train.copy()\ntest_hepatomegaly = test.copy()\n\n# KNNImputer pour les colonnes numériques pour l'imputation\nnum_cols = ['Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']\nimputer = KNNImputer(n_neighbors=122)\n\ntrain_hepatomegaly[num_cols] = imputer.fit_transform(train_hepatomegaly[num_cols])\ntest_hepatomegaly[num_cols] = imputer_test.fit_transform(test_hepatomegaly[num_cols])\n\ntrain_hepatomegaly.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_hepatomegaly['Hepatomegaly_missing'] = train_hepatomegaly['Hepatomegaly'].isna().astype(int)\n\nlabel_encoders = {}\ncategorical_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    train_hepatomegaly[col] = train_hepatomegaly[col].astype(str)\n    train_hepatomegaly[col] = le.fit_transform(train_hepatomegaly[col])\n    label_encoders[col] = le\n\nnot_null_data = train_hepatomegaly[train_hepatomegaly['Hepatomegaly_missing'] == 0]\nnull_data = train_hepatomegaly[train_hepatomegaly['Hepatomegaly_missing'] == 1]\n\nif null_data.empty:\n    print(\"Aucune valeur manquante pour 'Hepatomegaly'.\")\nelse:\n    features = [\n        col for col in train_hepatomegaly.columns\n        if col not in ['Hepatomegaly', 'Hepatomegaly_missing', 'Status']\n           and train_hepatomegaly[col].isna().sum() == 0\n    ]\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        not_null_data[features],\n        not_null_data['Hepatomegaly'],\n        test_size=0.2,\n        random_state=42\n    )\n    \n    randfor = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1)\n    param_grid = {\n        'criterion': ['gini', 'entropy'],\n        'max_depth': np.arange(1, 10)\n    }\n    gridmodel = GridSearchCV(randfor, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    gridmodel.fit(X_train, y_train)\n    \n    print(\"Meilleurs paramètres :\", gridmodel.best_params_)\n    best_model = gridmodel.best_estimator_\n    \n    test_predictions = best_model.predict(X_test)\n    accuracy = round((test_predictions == y_test).sum() / len(test_predictions), 3)\n    print(f\"Précision sur l'ensemble de test : {accuracy}\")\n\n    predicted_values = best_model.predict(null_data[features])\n    train_hepatomegaly.loc[train_hepatomegaly['Hepatomegaly_missing'] == 1, 'Hepatomegaly'] = predicted_values\n\ntrain_hepatomegaly['Hepatomegaly'] = label_encoders['Hepatomegaly'].inverse_transform(\n    train_hepatomegaly['Hepatomegaly'].astype(int)\n)\n\ntrain_hepatomegaly.drop('Hepatomegaly_missing', axis=1, inplace=True)\ntrain_hepatomegaly[['Hepatomegaly']].head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_hepatomegaly['Hepatomegaly_missing'] = test_hepatomegaly['Hepatomegaly'].isna().astype(int)\n\nlabel_encoders = {}\ncategorical_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    test_hepatomegaly[col] = test_hepatomegaly[col].astype(str)\n    test_hepatomegaly[col] = le.fit_transform(test_hepatomegaly[col])\n    label_encoders[col] = le\n\nnot_null_data = test_hepatomegaly[test_hepatomegaly['Hepatomegaly_missing'] == 0]\nnull_data = test_hepatomegaly[test_hepatomegaly['Hepatomegaly_missing'] == 1]\n\nif null_data.empty:\n    print(\"Aucune valeur manquante pour 'Hepatomegaly'.\")\nelse:\n    features = [\n        col for col in test_hepatomegaly.columns\n        if col not in ['Hepatomegaly', 'Hepatomegaly_missing', 'Status']\n           and test_hepatomegaly[col].isna().sum() == 0\n    ]\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        not_null_data[features],\n        not_null_data['Hepatomegaly'],\n        test_size=0.2,\n        random_state=42\n    )\n    \n    randfor = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1)\n    param_grid = {\n        'criterion': ['gini', 'entropy'],\n        'max_depth': np.arange(1, 10)\n    }\n    gridmodel = GridSearchCV(randfor, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    gridmodel.fit(X_train, y_train)\n    \n    print(\"Meilleurs paramètres :\", gridmodel.best_params_)\n    best_model = gridmodel.best_estimator_\n    \n    test_predictions = best_model.predict(X_test)\n    accuracy = round((test_predictions == y_test).sum() / len(test_predictions), 3)\n    print(f\"Précision sur l'ensemble de test : {accuracy}\")\n\n    predicted_values = best_model.predict(null_data[features])\n    test_hepatomegaly.loc[test_hepatomegaly['Hepatomegaly_missing'] == 1, 'Hepatomegaly'] = predicted_values\n\ntest_hepatomegaly['Hepatomegaly'] = label_encoders['Hepatomegaly'].inverse_transform(\n    test_hepatomegaly['Hepatomegaly'].astype(int)\n)\n\ntest_hepatomegaly.drop('Hepatomegaly_missing', axis=1, inplace=True)\ntest_hepatomegaly[['Hepatomegaly']].head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_spiders = train.copy()\ntest_spiders = test.copy()\n\n# KNNImputer pour les colonnes numériques pour l'imputation\nnum_cols = ['Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']\nimputer = KNNImputer(n_neighbors=122)\n\ntrain_spiders[num_cols] = imputer.fit_transform(train_spiders[num_cols])\ntest_spiders[num_cols] = imputer_test.fit_transform(test_spiders[num_cols])\ntrain_spiders.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_spiders['Spiders_missing'] = train_spiders['Spiders'].isna().astype(int)\n\nlabel_encoders = {}\ncategorical_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    train_spiders[col] = train_spiders[col].astype(str)\n    train_spiders[col] = le.fit_transform(train_spiders[col])\n    label_encoders[col] = le\n\nnot_null_data = train_spiders[train_spiders['Spiders_missing'] == 0]\nnull_data = train_spiders[train_spiders['Spiders_missing'] == 1]\n\nif null_data.empty:\n    print(\"Aucune valeur manquante pour 'Spiders'.\")\nelse:\n    features = [\n        col for col in train_spiders.columns\n        if col not in ['Spiders', 'Spiders_missing', 'Status']\n           and train_spiders[col].isna().sum() == 0\n    ]\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        not_null_data[features],\n        not_null_data['Spiders'],\n        test_size=0.2,\n        random_state=42\n    )\n    \n    randfor = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1)\n    param_grid = {\n        'criterion': ['gini', 'entropy'],\n        'max_depth': np.arange(1, 10)\n    }\n    gridmodel = GridSearchCV(randfor, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    gridmodel.fit(X_train, y_train)\n    \n    print(\"Meilleurs paramètres :\", gridmodel.best_params_)\n    best_model = gridmodel.best_estimator_\n    \n    test_predictions = best_model.predict(X_test)\n    accuracy = round((test_predictions == y_test).sum() / len(test_predictions), 3)\n    print(f\"Précision sur l'ensemble de test : {accuracy}\")\n\n    predicted_values = best_model.predict(null_data[features])\n    train_spiders.loc[train_spiders['Spiders_missing'] == 1, 'Spiders'] = predicted_values\n\ntrain_spiders['Spiders'] = label_encoders['Spiders'].inverse_transform(\n    train_spiders['Spiders'].astype(int)\n)\n\ntrain_spiders.drop('Spiders_missing', axis=1, inplace=True)\ntrain_spiders[['Spiders']].head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_spiders['Spiders_missing'] = test_spiders['Spiders'].isna().astype(int)\n\nlabel_encoders = {}\ncategorical_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    test_spiders[col] = test_spiders[col].astype(str)\n    test_spiders[col] = le.fit_transform(test_spiders[col])\n    label_encoders[col] = le\n\nnot_null_data = test_spiders[test_spiders['Spiders_missing'] == 0]\nnull_data = test_spiders[test_spiders['Spiders_missing'] == 1]\n\nif null_data.empty:\n    print(\"Aucune valeur manquante pour 'Spiders'.\")\nelse:\n    features = [\n        col for col in test_spiders.columns\n        if col not in ['Spiders', 'Spiders_missing', 'Status']\n           and test_spiders[col].isna().sum() == 0\n    ]\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        not_null_data[features],\n        not_null_data['Spiders'],\n        test_size=0.2,\n        random_state=42\n    )\n    \n    randfor = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1)\n    param_grid = {\n        'criterion': ['gini', 'entropy'],\n        'max_depth': np.arange(1, 10)\n    }\n    gridmodel = GridSearchCV(randfor, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    gridmodel.fit(X_train, y_train)\n    \n    print(\"Meilleurs paramètres :\", gridmodel.best_params_)\n    best_model = gridmodel.best_estimator_\n    \n    test_predictions = best_model.predict(X_test)\n    accuracy = round((test_predictions == y_test).sum() / len(test_predictions), 3)\n    print(f\"Précision sur l'ensemble de test : {accuracy}\")\n\n    predicted_values = best_model.predict(null_data[features])\n    test_spiders.loc[test_spiders['Spiders_missing'] == 1, 'Spiders'] = predicted_values\n\ntest_spiders['Spiders'] = label_encoders['Spiders'].inverse_transform(\n    test_spiders['Spiders'].astype(int)\n)\n\ntest_spiders.drop('Spiders_missing', axis=1, inplace=True)\ntest_spiders[['Spiders']].head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id_drug_df = train_drug[['id', 'Drug']]\nid_ascites_df = train_ascites[['id', 'Ascites']]\nid_hepatomegaly_df = train_hepatomegaly[['id', 'Hepatomegaly']]\nid_spiders_df = train_spiders[['id', 'Spiders']]\n\nid_drug_df_test = test_drug[['id', 'Drug']]\nid_ascites_df_test = test_ascites[['id', 'Ascites']]\nid_hepatomegaly_df_test = test_hepatomegaly[['id', 'Hepatomegaly']]\nid_spiders_df_test = test_spiders[['id', 'Spiders']]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_clean = train.copy()\ntest_clean = test.copy()\n\n# KNNImputer pour les colonnes numériques pour l'imputation\nnum_cols = ['Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']\nimputer = KNNImputer(n_neighbors=122)\n\ntrain_clean[num_cols] = imputer.fit_transform(train_clean[num_cols])\ntest_clean[num_cols] = imputer_test.fit_transform(test_clean[num_cols])\ntrain_clean.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns_to_drop = ['Drug', 'Ascites', 'Hepatomegaly', 'Spiders']\ntrain_clean = train_clean.drop(columns=columns_to_drop, errors='ignore')\ntest_clean = test_clean.drop(columns=columns_to_drop, errors='ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_clean = train_clean.merge(id_drug_df, on='id', how='left')\ntrain_clean = train_clean.merge(id_ascites_df, on='id', how='left')\ntrain_clean = train_clean.merge(id_hepatomegaly_df, on='id', how='left')\ntrain_clean = train_clean.merge(id_spiders_df, on='id', how='left')\n\ntest_clean = test_clean.merge(id_drug_df_test, on='id', how='left')\ntest_clean = test_clean.merge(id_ascites_df_test, on='id', how='left')\ntest_clean = test_clean.merge(id_hepatomegaly_df_test, on='id', how='left')\ntest_clean = test_clean.merge(id_spiders_df_test, on='id', how='left')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_clean.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_clean.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_clean.head(10)\ntest_clean['N_Days'].fillna(test_clean['N_Days'].median(skipna=True), inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_clean.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_clean.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_clean_copy = train_clean.copy()\ntest_clean_copy = test_clean.copy()\n\n# Normalisation avec PowerTransformer: pour rendre les données plus gaussienne\ncolonnes_to_normalize = ['Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos', \n                        'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']\n\ntransformer = PowerTransformer(method = 'yeo-johnson')\ntrain_clean_copy[colonnes_to_normalize] = transformer.fit_transform(train_clean_copy[colonnes_to_normalize])\ntest_clean_copy[colonnes_to_normalize] = transformer.fit_transform(test_clean_copy[colonnes_to_normalize])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in train_clean_copy.select_dtypes(include=['object']).columns:\n    unique_values = ', '.join(map(str, train_clean_copy[col].unique()))\n    print(f\"Colonne '{col}': {unique_values}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_clean_copy['Stage'][:3]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Custom Mapping pour Stage car l'ordre a l'air d'avoir son importance \n# This encoding is particularly useful for ordinal variable where the order of categories is important\n# To make sure that the learning algorithm interprets the ordinal variables correctly, \n# we can map the categorical values to integer values manually. \nprint(train_clean_copy['Stage'].unique())  \ntrain_clean_copy['Stage'] = train_clean_copy['Stage'].map({1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3})\ntest_clean_copy['Stage'] = test_clean_copy['Stage'].map({1.0: 0, 2.0: 1, 3.0: 2, 4.0: 3})\nprint(train_clean_copy['Stage'].unique())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# OneHot encoding pour les autres\n# Liste des colonnes catégoriques\ncolonnes_cat = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n\ntrain_clean_copy_encoded = pd.get_dummies(train_clean_copy, columns=colonnes_cat, drop_first=False)\ntest_clean_copy_encoded = pd.get_dummies(test_clean_copy, columns=colonnes_cat, drop_first=False)\ntrain_clean_copy_encoded.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_clean_copy_encoded.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# la colonne cible avec Label Encoding\nlabel_encoder = LabelEncoder()\ntrain_clean_copy_encoded['Status_encoded'] = label_encoder.fit_transform(train_clean_copy_encoded['Status']) \ntrain_clean_copy_encoded.drop('Status', axis=1, inplace=True)\ntrain_clean_copy_encoded['Status_encoded'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# le modèle \nX = train_clean_copy_encoded.drop(['id', 'Status_encoded'], axis=1) \ny = train_clean_copy_encoded['Status_encoded']  \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=10000)\n# solver='lbfgs' par défaut\n\nmodel.fit(X_train, y_train)\n\ny_pred_proba = model.predict_proba(X_test)\n\nlogloss = log_loss(y_test, y_pred_proba)\nprint(f\"Log Loss: {logloss}\")\n\ny_pred = model.predict(X_test)\nprint(classification_report(y_test, y_pred, target_names=['C', 'CL', 'D']))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_clean_copy_encoded","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train_clean_copy_encoded.drop(['id', 'Status_encoded'], axis=1)\ny = train_clean_copy_encoded['Status_encoded']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\nxgb_model = xgb.XGBClassifier(\n    objective='multi:softprob', # Pour prédire les probabilités pour chaque classe\n    num_class=3,                # Nombre de classes (C, CL, D)\n    eval_metric='mlogloss',     # Log-loss pour l'évaluation\n    use_label_encoder=False,    # Pour éviter les avertissements (à partir de XGBoost v1.3.0)\n    max_depth=6,                # Profondeur de l'arbre (à ajuster selon les données)\n    learning_rate=0.1,          # Taux d'apprentissage\n    n_estimators=100,           # Nombre d'arbres (à ajuster pour éviter le sur-apprentissage)\n    subsample=0.8,              # Fraction d'échantillons utilisée pour chaque arbre\n    colsample_bytree=0.8,       # Fraction des colonnes utilisées pour chaque arbre\n    seed=42                     # Pour la reproductibilité\n)\n\nxgb_model.fit(X_train, y_train)\n\ny_pred_proba = xgb_model.predict_proba(X_test)\n\nlogloss = log_loss(y_test, y_pred_proba)\nprint(f\"Log Loss avec XGBoost : {logloss:.4f}\")\n\ny_pred = xgb_model.predict(X_test)\n\nprint(classification_report(y_test, y_pred, target_names=['C', 'CL', 'D']))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_final = test_clean_copy_encoded.drop(['id'], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_final.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test_proba = xgb_model.predict_proba(X_test_final)\n\ndf_results = test_clean_copy_encoded[['id']].copy()\ndf_results['Status_C'] = y_test_proba[:, 0]\ndf_results['Status_CL'] = y_test_proba[:, 1]\ndf_results['Status_D'] = y_test_proba[:, 2]\n\ndf_results.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}